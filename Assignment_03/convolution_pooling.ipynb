{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Fundamentals - Neural Networks - Exercise: Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Requirements](#Requirements) \n",
    "  * [Knowledge](#Knowledge) \n",
    "  * [Modules](#Python-Modules) \n",
    "  * [Data](#Data)\n",
    "* [Convolution and Maxpool Layer](#Convolution-and-Maxpool-Layer)\n",
    "  * [Todo: Kernels](#Kernels)\n",
    "  * [Todo: Convolution](#Convolution)\n",
    "  * [Todo: Pooling](#Pooling)\n",
    "  * [Todo: Experiments](#Experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge\n",
    "By now you should be familiar with the convolution operation, but you may want to repeat some information again. Following source are recommended:\n",
    "- [1163050 Lecture Slides](http://home.htw-berlin.de/~voigtb/content/slides/1163150_lecture_05.pdf)\n",
    "- [cs231n ConvNets Lecture Notes](http://cs231n.github.io/convolutional-networks/)\n",
    "- [Colah's Blog](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# third party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.signal \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "For the exercise i used the 'Photo of the Day' (6.6.2018) from Unsplash.com by Adrian Trinkaus. You can change it at will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an image\n",
    "img = Image.open('pics/berlin_adrian-trinkaus.jpg')\n",
    "# Convert it to greyscale and RGB\n",
    "img_gry = img.convert('L')\n",
    "img_rgb = img.convert('RGB')\n",
    " \n",
    "# Create a numpy array with dimensions (height, width, channel)\n",
    "# and squash all values into interval [0,1]\n",
    "img_gry = np.asarray(img_gry)/256.\n",
    "img_rgb = np.asarray(img_rgb)/256.\n",
    "\n",
    "# Print array shapes\n",
    "print('grayscale shape:', img_gry.shape)\n",
    "print('rgb shape:', img_rgb.shape)\n",
    "\n",
    "# Example plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharey=True,figsize=(15,15))\n",
    "ax1.imshow(img_gry, cmap=\"Greys_r\")\n",
    "ax2.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution and Maxpool Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels \n",
    "**(2)**\n",
    "Cause we do not learn the filters during the exercise we will need some for your experiments. Some Filters are given and you should create at least two more. Do a small research about 'image processing filters' and pick what you like. Remember that your Kernels need to have the same depth as your input. You may consider this issue during your implementation of the convolution operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# typical edge detection filter\n",
    "class Kernels:\n",
    "    def __init__(self):\n",
    "        self.edge_detector_1_2d = np.array([[0., 1., 0.],[1., -4., 1.],[0., 1., 0.]])\n",
    "        self.edge_detector_2_2d = np.array([[1., 0., -1.],[0., 0., 0.],[-1., 0., 1.]])\n",
    "        self.edge_detector_3_2d = np.array([[-1., -1., -1.],[-1., 8., -1.],[-1., -1., -1.]])\n",
    "        self.sobel_2d = np.array([[1.,2.,1.],[0.,0.,0],[-1.,-2.,-1.]])\n",
    "        self.gauss_2d = self.blur()\n",
    "        self.sharpen_2d = np.array([[0., -1., 0.],[-1., 5., -1.],[0., -1., 0.]])\n",
    "        self.box_blur_2d = 1/9 * np.array([[1., 1., 1.],[1., 1., 1.],[1., 1., 1.]])\n",
    "        self.identity_2d = np.array([[0., 0., 0.],[0., 1., 0.],[0., 0., 0.]])\n",
    "        \n",
    "    def blur(self):\n",
    "        gauss_1d = scipy.signal.get_window(('gaussian',1.),15)\n",
    "        gauss_2d = np.outer(gauss_1d,gauss_1d)\n",
    "        return gauss_2d/gauss_2d.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "**(5)** \n",
    "Create a `Conv` class that implements a (naive) convolution operation on _one_ image at the time. Do not use any module, your goal is to get a better understanding for a 2d-conv operation. If your input has more as one channel apply on each the same conv-operation. Document your code and follow the  specification. After your implementation, give a statement about the runtime of your algorithm based on the $O$ notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fragen \n",
    "* Was macht man mit ungeraden Paddings (z.B. P = 1.5)? \n",
    "* drüfen wir nicht mal numpy als modul verwenden?\n",
    "* Wenn es mehr channel gibt zb. dim = (4,4,3) soll dann die outut dim = (.,.,3) oder (.,.,1) sein?\n",
    "* Soll noch mehr Kommentiert werden? z.B. einzelne Code-Lines?\n",
    "* Sollen wir etwas ausgeben? (wegen des verbose Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self, image_dim, kernel, stride=1, padding=True, verbose=True):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            image_dim: dimension of the squared image \n",
    "            kernel: a filter for the convulution\n",
    "            stride: step size with which the kernel slides over the image\n",
    "            padding: if set zero padding will be applied to keep image dimensions\n",
    "            verbose: if set additional information will be printed, e.g., input and output dimensions\n",
    "        \"\"\"\n",
    "        self.image_dim = image_dim\n",
    "        self.padding = int(((image_dim[0]-1)*stride-image_dim[0]+kernel.shape[0])/2 if padding else 0)\n",
    "        self.kernel = kernel\n",
    "        self.kernel_size = kernel.shape[0]\n",
    "        self.stride = stride\n",
    "        self.verbose = verbose\n",
    "        # The dimensions of the Conv output.\n",
    "        self.output_dim = self.output_dimension()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        \"\"\" Executes a convolution on the given image with init params  \n",
    "        \n",
    "        Args:\n",
    "            image (ndarray): squared image \n",
    "        \n",
    "        Returns:    \n",
    "            ndarray: activation map\n",
    "        \"\"\"\n",
    "        # Initialize the output volume with zeros.\n",
    "        output = np.zeros(self.output_dim)\n",
    "        \n",
    "        # Calculate image with padding and new image dimension.\n",
    "        image, self.image_dim = self.zero_padding(image)\n",
    "        \n",
    "        for h in tqdm(range(self.output_dim[0])):  # loop over height indices of the output volume.\n",
    "            for w in range(self.output_dim[1]):  # loop over width indices of the output volume.\n",
    "                \n",
    "                # Indices if the current image part that sould be used for computation.\n",
    "                image_H_i_start = h * self.stride\n",
    "                image_H_i_end = image_H_i_start + self.kernel_size\n",
    "                image_W_i_start = w * self.stride\n",
    "                image_W_i_end = image_W_i_start + self.kernel_size\n",
    "                \n",
    "                if len(self.image_dim) == 3:   \n",
    "                    for c in range(self.image_dim[2]):  # loop over channel indices of the image.\n",
    "                        output[h,w] += np.sum(image[image_H_i_start:image_H_i_end,image_W_i_start:image_W_i_end,c] * self.kernel)\n",
    "                else:\n",
    "                    output[h,w] = np.sum(image[image_H_i_start:image_H_i_end,image_W_i_start:image_W_i_end] * self.kernel)\n",
    "                    \n",
    "        return output\n",
    "    \n",
    "    def zero_padding(self, image):\n",
    "        \"\"\" Add zero padding to the given image.  \n",
    "        \n",
    "        Args:\n",
    "            image (ndarray): squared image \n",
    "        \n",
    "        Returns:    \n",
    "            ndarray: zero padded image\n",
    "            tuple: dimension of the padded image\n",
    "        \"\"\"\n",
    "    \n",
    "        # self.padding == 0 no padding needs to be added\n",
    "        if self.padding == 0:\n",
    "            return image, image.shape\n",
    "        \n",
    "        # Calculate height dimension of padded image\n",
    "        padded_H_dim = self.image_dim[0] + 2 * self.padding\n",
    "        \n",
    "        # Calculate width dimension of padded image\n",
    "        padded_W_dim = self.image_dim[1] + 2 * self.padding\n",
    "        \n",
    "        if len(self.image_dim) == 3:\n",
    "            padded_image_dim = (padded_H_dim, padded_W_dim, self.image_dim[2])\n",
    "        else:\n",
    "            padded_image_dim = (padded_H_dim, padded_W_dim)\n",
    "            \n",
    "        # Initalize padded image with zeros\n",
    "        padded_image = np.zeros(padded_image_dim)\n",
    "        \n",
    "        # Fill padded image with image values\n",
    "        padded_image[self.padding:-self.padding, self.padding:-self.padding] = image\n",
    "        \n",
    "        # Assert if shape of padded image is correct\n",
    "        assert(padded_image.shape == padded_image_dim)\n",
    "    \n",
    "        return padded_image, padded_image.shape\n",
    "    \n",
    "    def output_dimension(self):\n",
    "        \"\"\" Compute the dimensions of the CONV output volume.  \n",
    "        \n",
    "        Returns:    \n",
    "            tuple: output dimensions\n",
    "        \"\"\"\n",
    "        # Height of the Conv output volume.\n",
    "        h = int((self.image_dim[0] - self.kernel_size + 2 * self.padding) / self.stride) + 1\n",
    "        # Width of the Conv output volume.\n",
    "        w = int((self.image_dim[1] - self.kernel_size + 2 * self.padding) / self.stride) + 1\n",
    "        \n",
    "        return (h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "**(2)** \n",
    "Create a `Pooling` class that implements the pooling operation with different functions (max, sum, mean) on a given image. Document your code and follow the specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fragen\n",
    "* Soll noch mehr Kommentiert werden? z.B. einzelne Code-Lines?\n",
    "* Sollen wir etwas ausgeben? (wegen des verbose Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pooling():\n",
    "    def __init__(self, image_dim, pooling_function=None, pooling_size=2, stride=2, verbose=True):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            image_dim: dimension of the squared image \n",
    "            pooling_function: defines the pooling operator 'max' (default), 'mean' or 'sum'\n",
    "            poolig_size: size of one axis of the squared pooling filter\n",
    "            stride: step size with which the filter slides over the image\n",
    "            verbose: if set additional information will be printed, e.g., input and output dimensions\n",
    "        \"\"\"\n",
    "        self.image_dim = image_dim\n",
    "        self.pooling_function = np.max if pooling_function is None else pooling_function\n",
    "        self.pooling_size = pooling_size \n",
    "        self.stride = stride\n",
    "        self.verbose = verbose \n",
    "        self.output_dim = self.output_dimension()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        \"\"\" Executes pooling on the given image with init params  \n",
    "        \n",
    "        Args:\n",
    "            image (ndarray): squared image \n",
    "        \n",
    "        Returns:    \n",
    "            ndarray: activation map\n",
    "        \"\"\"\n",
    "        # Initialize the output volume with zeros.\n",
    "        output = np.zeros(self.output_dim)\n",
    "        \n",
    "        for h in tqdm(range(self.output_dim[0])):  # loop over height indices of the output volume.\n",
    "            for w in range(self.output_dim[1]):  # loop over width indices of the output volume.\n",
    "                \n",
    "                # Indices if the current image part that sould be used for computation.\n",
    "                image_H_i_start = h * self.stride\n",
    "                image_H_i_end = image_H_i_start + self.pooling_size\n",
    "                image_W_i_start = w * self.stride\n",
    "                image_W_i_end = image_W_i_start + self.pooling_size\n",
    "                \n",
    "                if len(self.image_dim) == 3:\n",
    "                    for c in range(self.image_dim[2]):  # loop over channels indices of image.\n",
    "                        output[h,w,c] = self.pooling_function(image[image_H_i_start:image_H_i_end,image_W_i_start:image_W_i_end,c])\n",
    "                else:\n",
    "                    output[h,w] = self.pooling_function(image[image_H_i_start:image_H_i_end,image_W_i_start:image_W_i_end])\n",
    "                    \n",
    "        return output\n",
    "    \n",
    "    def output_dimension(self):\n",
    "        \"\"\" Compute the dimensions of the CONV output volume.  \n",
    "        \n",
    "        Returns:    \n",
    "            tuple: output dimensions\n",
    "        \"\"\"\n",
    "        # Height of the Conv output volume.\n",
    "        h = int((self.image_dim[0] - self.pooling_size) / self.stride) + 1\n",
    "        # Width of the Conv output volume.\n",
    "        w = int((self.image_dim[1] - self.pooling_size) / self.stride) + 1\n",
    "        \n",
    "        # If the image has a channel dimension this is added to the dimension of the Conv output volume.\n",
    "        if len(self.image_dim) == 3:\n",
    "            return (h, w, self.image_dim[2])\n",
    "        else:\n",
    "            return (h, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "**(3)**\n",
    "Use the data (you may want to try some more images) and different kernel to do some experiments with your implementations. Plot results of convolution operations and compare them. What happens if you stack several convolution operations? What are the differences between the pooling functions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fragen\n",
    "* Wie viel sollen wir testen?\n",
    "* Sollen wir die gestellten Fragen schriftlich beantworten?\n",
    "* Sollen wir auch Convs- zusammen mit Pooling-Layern stacken?\n",
    "* Muss beim plotten der gray scale conv results auch cmap=\"Greys_r\" angegeben werden?\n",
    "* soll überhaupt farbe ausgegeben werden bei conv results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(img1, img2, conv=True):\n",
    "    \"\"\" Plots two Conv ouput images . \n",
    "        \n",
    "    Args:\n",
    "        img1 (ndarray): squared image (channel dimension = 1)\n",
    "        img2 (ndarray): squared image (channel dimension should be 1 if conv = True else should be 3)\n",
    "    \"\"\"\n",
    "    # Print array shapes\n",
    "    print('image no. 1 shape:', img1.shape)\n",
    "    print('image no. 2 shape:', img2.shape)\n",
    "\n",
    "    # Example plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, sharey=True,figsize=(15,15))\n",
    "    ax1.imshow(img1, cmap=\"Greys_r\")\n",
    "    if conv:\n",
    "        ax2.imshow(img2, cmap=\"Greys_r\")\n",
    "    else:\n",
    "        ax2.imshow(img2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernels = Kernels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the `edge_detector_1_2` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.edge_detector_1_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.edge_detector_1_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the `edge_detector_2_2` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.edge_detector_2_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.edge_detector_2_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the `edge_detector_3_2` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.edge_detector_3_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.edge_detector_3_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the `sobel_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.sobel_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.sobel_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the `gauss_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.gauss_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.gauss_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the `sharpen_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.sharpen_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.sharpen_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the `box_blur_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.box_blur_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.box_blur_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the `identity_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.identity_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.identity_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Pooling(img_gry.shape).forward(img_gry),\n",
    "    Pooling(img_rgb.shape).forward(img_rgb),\n",
    "    conv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Testing mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Pooling(img_gry.shape, np.mean).forward(img_gry),\n",
    "    Pooling(img_rgb.shape, np.mean).forward(img_rgb),\n",
    "    conv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Pooling(img_gry.shape, np.sum, pooling_size=10).forward(img_gry),\n",
    "    Pooling(img_rgb.shape, np.sum, pooling_size=10).forward(img_rgb),\n",
    "    conv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Pooling(img_gry.shape, np.min, pooling_size=10).forward(img_gry),\n",
    "    Pooling(img_rgb.shape, np.min, pooling_size=10).forward(img_rgb),\n",
    "    conv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [Kernels().identity_2d, Kernels().sharpen_2d]\n",
    "\n",
    "img_gry_conv_result = img_gry\n",
    "img_rgb_conv_result = img_rgb\n",
    "\n",
    "for kernel in kernels:\n",
    "    img_gry_conv = Conv(img_gry_conv_result.shape, kernel)\n",
    "    img_gry_conv_result = img_gry_conv.forward(img_gry_conv_result)\n",
    "\n",
    "    img_rgb_conv = Conv(img_rgb_conv_result.shape, kernel)\n",
    "    img_rgb_conv_result = img_rgb_conv.forward(img_rgb_conv_result)\n",
    "\n",
    "print_images(\n",
    "    img_gry_conv_result,\n",
    "    img_rgb_conv_result\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [Kernels().sharpen_2d, Kernels().identity_2d]\n",
    "\n",
    "img_gry_conv_result = img_gry\n",
    "img_rgb_conv_result = img_rgb\n",
    "\n",
    "for kernel in kernels:\n",
    "    img_gry_conv = Conv(img_gry_conv_result.shape, kernel)\n",
    "    img_gry_conv_result = img_gry_conv.forward(img_gry_conv_result)\n",
    "\n",
    "    img_rgb_conv = Conv(img_rgb_conv_result.shape, kernel)\n",
    "    img_rgb_conv_result = img_rgb_conv.forward(img_rgb_conv_result)\n",
    "\n",
    "print_images(\n",
    "    img_gry_conv_result,\n",
    "    img_rgb_conv_result\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Convs and Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_function = np.min\n",
    "\n",
    "img_gry_pool = Pooling(img_gry_conv_result.shape, pooling_function)\n",
    "img_gry_pool_result = img_gry_pool.forward(img_gry_conv_result)\n",
    "\n",
    "img_rgb_pool = Pooling(img_rgb_conv_result.shape, pooling_function)\n",
    "img_rgb_pool_result = img_rgb_pool.forward(img_rgb_conv_result)\n",
    "\n",
    "print_images(\n",
    "    img_gry_pool_result,\n",
    "    img_rgb_pool_result\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
