{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Fundamentals - Neural Networks - Exercise: Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Requirements](#Requirements) \n",
    "  * [Knowledge](#Knowledge) \n",
    "  * [Modules](#Python-Modules) \n",
    "  * [Data](#Data)\n",
    "* [Convolution and Maxpool Layer](#Convolution-and-Maxpool-Layer)\n",
    "  * [Todo: Kernels](#Kernels)\n",
    "  * [Todo: Convolution](#Convolution)\n",
    "  * [Todo: Pooling](#Pooling)\n",
    "  * [Todo: Experiments](#Experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge\n",
    "By now you should be familiar with the convolution operation, but you may want to repeat some information again. Following source are recommended:\n",
    "- [1163050 Lecture Slides](http://home.htw-berlin.de/~voigtb/content/slides/1163150_lecture_05.pdf)\n",
    "- [cs231n ConvNets Lecture Notes](http://cs231n.github.io/convolutional-networks/)\n",
    "- [Colah's Blog](http://colah.github.io/posts/2014-07-Understanding-Convolutions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python-Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# third party\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.signal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "For the exercise i used the 'Photo of the Day' (6.6.2018) from Unsplash.com by Adrian Trinkaus. You can change it at will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "img = Image.open('pics/berlin_adrian-trinkaus.jpg')\n",
    "# Convert it to greyscale and RGB\n",
    "img_gry = img.convert('L')\n",
    "img_rgb = img.convert('RGB')\n",
    " \n",
    "# Create a numpy array with dimensions (height, width, channel)\n",
    "# and squash all values into interval [0,1]\n",
    "img_gry = np.asarray(img_gry)/256.\n",
    "img_rgb = np.asarray(img_rgb)/256.\n",
    "\n",
    "# Print array shapes\n",
    "print('grayscale shape:', img_gry.shape)\n",
    "print('rgb shape:', img_rgb.shape)\n",
    "\n",
    "# Example plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharey=True,figsize=(15,15))\n",
    "ax1.imshow(img_gry, cmap=\"Greys_r\")\n",
    "ax2.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution and Maxpool Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels \n",
    "**(2)**\n",
    "Cause we do not learn the filters during the exercise we will need some for your experiments. Some Filters are given and you should create at least two more. Do a small research about 'image processing filters' and pick what you like. Remember that your Kernels need to have the same depth as your input. You may consider this issue during your implementation of the convolution operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# typical edge detection filter\n",
    "class Kernels:\n",
    "    def __init__(self):\n",
    "        self.edge_detector_1_2d = np.array([[0., 1., 0.],[1., -4., 1.],[0., 1., 0.]])\n",
    "        self.edge_detector_2_2d = np.array([[1., 0., -1.],[0., 0., 0.],[-1., 0., 1.]])\n",
    "        self.edge_detector_3_2d = np.array([[-1., -1., -1.],[-1., 8., -1.],[-1., -1., -1.]])\n",
    "        self.sobel_2d = np.array([[1.,2.,1.],[0.,0.,0],[-1.,-2.,-1.]])\n",
    "        self.gauss_2d = self.blur()\n",
    "        self.sharpen_2d = np.array([[0., -1., 0.],[-1., 5., -1.],[0., -1., 0.]])\n",
    "        self.box_blur_2d = 1/9 * np.array([[1., 1., 1.],[1., 1., 1.],[1., 1., 1.]])\n",
    "        self.identity_2d = np.array([[0., 0., 0.],[0., 1., 0.],[0., 0., 0.]])\n",
    "        \n",
    "    def blur(self):\n",
    "        gauss_1d = scipy.signal.get_window(('gaussian',1.),15)\n",
    "        gauss_2d = np.outer(gauss_1d,gauss_1d)\n",
    "        return gauss_2d/gauss_2d.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "**(5)** \n",
    "Create a `Conv` class that implements a (naive) convolution operation on _one_ image at the time. Do not use any module, your goal is to get a better understanding for a 2d-conv operation. If your input has more as one channel apply on each the same conv-operation. Document your code and follow the  specification. After your implementation, give a statement about the runtime of your algorithm based on the $O$ notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self, image_dim, kernel, stride=1, padding=True, verbose=True):\n",
    "        '''\n",
    "        Args:\n",
    "            image_dim: dimension of the squared image \n",
    "            kernel: a filter for the convolution\n",
    "            stride: step size with which the kernel slides over the image\n",
    "            padding: if set zero padding will be applied to keep image dimensions\n",
    "            verbose: if set additional information will be printed, e.g., input and output dimensions\n",
    "        '''\n",
    "        self.image_dim = image_dim\n",
    "        self.padding = self.calculate_padding(image_dim, kernel.shape[0], stride) if padding else 0\n",
    "        self.kernel = kernel\n",
    "        self.kernel_size = kernel.shape[0]\n",
    "        self.stride = stride\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, image):\n",
    "        ''' Executes a convolution on the given image with init params  \n",
    "        \n",
    "        Args:\n",
    "            image (ndarray): squared image \n",
    "        \n",
    "        Returns:    \n",
    "            ndarray: activation map\n",
    "        '''\n",
    "        # The dimensions of image.\n",
    "        in_H, in_W, in_C = self.image_dim\n",
    "        \n",
    "        # The dimensions of output.\n",
    "        out_H = int((in_H - self.kernel_size + 2 * self.padding) / self.stride) + 1\n",
    "        out_W = int((in_W - self.kernel_size + 2 * self.padding) / self.stride) + 1\n",
    "        out_C = 1\n",
    "        \n",
    "        # Initialize the output volume with zeros.\n",
    "        out = np.zeros((out_H, out_W, out_C))\n",
    "        \n",
    "        padded_image = np.pad(image,((self.padding,self.padding),(self.padding,self.padding),(0,0)),'constant',constant_values = 0)\n",
    "  \n",
    "        for h in range(out_H):                  # Loop over height indices of the output volume.\n",
    "            for w in range(out_W):              # Loop over width indices of the output volume.\n",
    "                for c in range(in_C):           # Loop over channel indices of the image.\n",
    "                \n",
    "                    # Corner indices of the window.\n",
    "                    image_h_start = h * self.stride\n",
    "                    image_h_end = image_h_start + self.kernel_size\n",
    "                    image_w_start = w * self.stride\n",
    "                    image_w_end = image_w_start + self.kernel_size\n",
    "                \n",
    "                    out[h,w,:] += np.sum(padded_image[image_h_start:image_h_end,image_w_start:image_w_end,c] * self.kernel)\n",
    "                \n",
    "        return out   \n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_padding(image_dim, kernel_size, stride):\n",
    "        ''' Calcluate padding.\n",
    "    \n",
    "        Args:\n",
    "            X_dim: Dimension of X.\n",
    "            filter_dim: Dimension of filter.\n",
    "            stride: stride.\n",
    "        Returns:\n",
    "            padding: Padding as integer.\n",
    "        Raise:\n",
    "            TypeError: If calculated padding is not an interger, an TypeError is raised.\n",
    "        '''\n",
    "        # Calculate padding\n",
    "        padding = ((image_dim[0] - 1) * stride - image_dim[0] + kernel_size) / 2\n",
    "        \n",
    "        # Check if padding is an interger\n",
    "        if padding.is_integer():\n",
    "            # Retrun padding as interger\n",
    "            return int(padding)\n",
    "        else:\n",
    "            # Raise TypeError if padding is not an interger\n",
    "            raise TypeError('Calculated padding is not an integer. Please choose a different kernel_size and/or stride!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "**(2)** \n",
    "Create a `Pooling` class that implements the pooling operation with different functions (max, sum, mean) on a given image. Document your code and follow the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pooling():\n",
    "    def __init__(self, image_dim, pooling_function=np.max, pooling_size=2, stride=2, verbose=True):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            image_dim: dimension of the squared image \n",
    "            pooling_function: defines the pooling operator 'max' (default), 'mean' or 'sum'\n",
    "            poolig_size: size of one axis of the squared pooling filter\n",
    "            stride: step size with which the filter slides over the image\n",
    "            verbose: if set additional information will be printed, e.g., input and output dimensions\n",
    "        \"\"\"\n",
    "        self.image_dim = image_dim\n",
    "        self.pooling_function = pooling_function\n",
    "        self.pooling_size = pooling_size \n",
    "        self.stride = stride\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, image):\n",
    "        \"\"\" Executes pooling on the given image with init params  \n",
    "        \n",
    "        Args:\n",
    "            image (ndarray): squared image \n",
    "        \n",
    "        Returns:    \n",
    "            ndarray: activation map\n",
    "        \"\"\"\n",
    "        # The dimensions of image.\n",
    "        in_H, in_W, in_C = self.image_dim\n",
    "        \n",
    "        # The dimensions of output.\n",
    "        out_H = int((in_H - self.pooling_size) / self.stride) + 1\n",
    "        out_W = int((in_W - self.pooling_size) / self.stride) + 1\n",
    "        out_C = in_C\n",
    "        \n",
    "        # Initialize the output volume with zeros.\n",
    "        out = np.zeros((out_H, out_W, out_C))\n",
    "        \n",
    "        for h in range(out_H):                  # Loop over height indices of the output volume.\n",
    "            for w in range(out_W):              # Loop over width indices of the output volume.\n",
    "                for c in range(out_C):          # Loop over channel indices of the output volume.\n",
    "                \n",
    "                    # Corner indices of the window.\n",
    "                    image_h_start = h * self.stride\n",
    "                    image_h_end = image_h_start + self.pooling_size\n",
    "                    image_w_start = w * self.stride\n",
    "                    image_w_end = image_w_start + self.pooling_size\n",
    "                \n",
    "                    out[h,w,c] = self.pooling_function(image[image_h_start:image_h_end,image_w_start:image_w_end,c])\n",
    "               \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "**(3)**\n",
    "Use the data (you may want to try some more images) and different kernel to do some experiments with your implementations. Plot results of convolution operations and compare them. What happens if you stack several convolution operations? What are the differences between the pooling functions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_gry = img_gry.reshape((660,660,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_images(img1, img2):\n",
    "    \"\"\" Plots two Conv ouput images . \n",
    "        \n",
    "    Args:\n",
    "        img1 (ndarray): squared image (channel dimension = 1)\n",
    "        img2 (ndarray): squared image (channel dimension should be 1 if conv = True else should be 3)\n",
    "    \"\"\"\n",
    "    if img1.shape[2] == 1:\n",
    "        img1 = img1.reshape((img1.shape[0],img1.shape[1]))\n",
    "    \n",
    "    if img2.shape[2] == 1:\n",
    "        img2 = img2.reshape((img2.shape[0],img2.shape[1]))\n",
    "    \n",
    "    # Print array shapes\n",
    "    print('image no. 1 shape:', img1.shape)\n",
    "    print('image no. 2 shape:', img2.shape)\n",
    "\n",
    "    # Example plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, sharey=True,figsize=(15,15))\n",
    "    \n",
    "    ax1.imshow(img1)\n",
    "    ax2.imshow(img2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Conv-Layer with different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernels = Kernels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `edge_detector_1_2` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.edge_detector_1_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.edge_detector_1_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `edge_detector_2_2` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.edge_detector_2_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.edge_detector_2_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `edge_detector_3_2` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.edge_detector_3_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.edge_detector_3_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `sobel_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.sobel_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.sobel_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `gauss_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.gauss_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.gauss_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `sharpen_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.sharpen_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.sharpen_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `box_blur_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.box_blur_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.box_blur_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the `identity_2d` as kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Conv(img_gry.shape, kernels.identity_2d).forward(img_gry),\n",
    "    Conv(img_rgb.shape, kernels.identity_2d).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Pooling-Layer with different Pooling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Pooling(img_gry.shape).forward(img_gry),\n",
    "    Pooling(img_rgb.shape).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Testing mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Pooling(img_gry.shape, np.mean).forward(img_gry),\n",
    "    Pooling(img_rgb.shape, np.mean).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Pooling(img_gry.shape, np.sum, pooling_size=10).forward(img_gry),\n",
    "    Pooling(img_rgb.shape, np.sum, pooling_size=10).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_images(\n",
    "    Pooling(img_gry.shape, np.min, pooling_size=10).forward(img_gry),\n",
    "    Pooling(img_rgb.shape, np.min, pooling_size=10).forward(img_rgb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Conv-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernels = [Kernels().identity_2d, Kernels().sharpen_2d]\n",
    "\n",
    "img_gry_conv_result = img_gry\n",
    "img_rgb_conv_result = img_rgb\n",
    "\n",
    "for kernel in kernels:\n",
    "    img_gry_conv = Conv(img_gry_conv_result.shape, kernel)\n",
    "    img_gry_conv_result = img_gry_conv.forward(img_gry_conv_result)\n",
    "\n",
    "    img_rgb_conv = Conv(img_rgb_conv_result.shape, kernel)\n",
    "    img_rgb_conv_result = img_rgb_conv.forward(img_rgb_conv_result)\n",
    "\n",
    "print_images(\n",
    "    img_gry_conv_result,\n",
    "    img_rgb_conv_result\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernels = [Kernels().sharpen_2d, Kernels().identity_2d]\n",
    "\n",
    "img_gry_conv_result = img_gry\n",
    "img_rgb_conv_result = img_rgb\n",
    "\n",
    "for kernel in kernels:\n",
    "    img_gry_conv = Conv(img_gry_conv_result.shape, kernel)\n",
    "    img_gry_conv_result = img_gry_conv.forward(img_gry_conv_result)\n",
    "\n",
    "    img_rgb_conv = Conv(img_rgb_conv_result.shape, kernel)\n",
    "    img_rgb_conv_result = img_rgb_conv.forward(img_rgb_conv_result)\n",
    "\n",
    "print_images(\n",
    "    img_gry_conv_result,\n",
    "    img_rgb_conv_result\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Conv- and Pooling-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pooling_function = np.min\n",
    "\n",
    "img_gry_pool = Pooling(img_gry_conv_result.shape, pooling_function)\n",
    "img_gry_pool_result = img_gry_pool.forward(img_gry_conv_result)\n",
    "\n",
    "img_rgb_pool = Pooling(img_rgb_conv_result.shape, pooling_function)\n",
    "img_rgb_pool_result = img_rgb_pool.forward(img_rgb_conv_result)\n",
    "\n",
    "print_images(\n",
    "    img_gry_pool_result,\n",
    "    img_rgb_pool_result\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
